{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJloE7VRFkFp",
        "outputId": "3e68a8c7-bd4a-401a-c865-5d4567e42b63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-30 selected features:\n",
            "['dur', 'proto', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl', 'dttl', 'sload', 'dload', 'sloss', 'dloss', 'sinpkt', 'dinpkt', 'sjit', 'djit', 'swin', 'stcpb', 'tcprtt', 'synack', 'ackdat', 'smean', 'dmean', 'ct_srv_src', 'ct_state_ttl', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_srv_dst']\n",
            "\n",
            ">>> Training & evaluating LogisticRegression\n",
            "\n",
            ">>> Training & evaluating RandomForest\n",
            "\n",
            ">>> Training & evaluating GradientBoosting\n",
            "\n",
            ">>> Training & evaluating KNN\n",
            "\n",
            ">>> Training & evaluating DecisionTree\n",
            "\n",
            "## Model Performance on ‘attack’ class:\n",
            "| Model              |   Precision |   Recall |   F1-score |   Accuracy |\n",
            "|:-------------------|------------:|---------:|-----------:|-----------:|\n",
            "| LogisticRegression |       95.17 |    86.97 |      90.88 |      88.12 |\n",
            "| RandomForest       |       97.95 |    88.69 |      93.09 |      91.04 |\n",
            "| GradientBoosting   |       98.13 |    88.32 |      92.97 |      90.9  |\n",
            "| KNN                |       97.06 |    84.25 |      90.2  |      87.54 |\n",
            "| DecisionTree       |       96.8  |    88.63 |      92.53 |      90.27 |\n",
            "\n",
            "### Model Performance on ‘attack’ class:\n",
            "| Model              |   Precision |   Recall |   F1-score |   Accuracy |\n",
            "|:-------------------|------------:|---------:|-----------:|-----------:|\n",
            "| LogisticRegression |     95.1653 |  86.9709 |    90.8838 |    88.1249 |\n",
            "| RandomForest       |     97.9539 |  88.6937 |    93.0941 |    91.0437 |\n",
            "| GradientBoosting   |     98.1296 |  88.3192 |    92.9663 |    90.904  |\n",
            "| KNN                |     97.0558 |  84.2493 |    90.2003 |    87.5403 |\n",
            "| DecisionTree       |     96.7988 |  88.6301 |    92.5345 |    90.2664 |\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "import pickle\n",
        "\n",
        "# 1. Paths to your CSVs\n",
        "TRAIN_CSV = 'UNSW_NB15_training-set.csv'\n",
        "TEST_CSV  = 'UNSW_NB15_testing-set.csv'\n",
        "assert os.path.exists(TRAIN_CSV), f\"{TRAIN_CSV} not found\"\n",
        "assert os.path.exists(TEST_CSV),  f\"{TEST_CSV} not found\"\n",
        "\n",
        "# 2. Load data\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "test_df  = pd.read_csv(TEST_CSV)\n",
        "\n",
        "# 3. Drop ID & attack category (already encoded in 'label')\n",
        "for df in (train_df, test_df):\n",
        "    df.drop(['id', 'attack_cat'], axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "# 4. Split features/target\n",
        "X_train = train_df.drop('label', axis=1)\n",
        "y_train = train_df['label']\n",
        "X_test  = test_df.drop('label', axis=1)\n",
        "y_test  = test_df['label']\n",
        "\n",
        "# 5. Encode any categorical cols\n",
        "for col in X_train.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    le.fit(pd.concat([X_train[col], X_test[col]], axis=0))\n",
        "    X_train[col] = le.transform(X_train[col])\n",
        "    X_test[col]  = le.transform(X_test[col])\n",
        "\n",
        "# 6. Scale\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "# 7. Feature selection (top 30 by mutual info)\n",
        "selector = SelectKBest(mutual_info_classif, k=30)\n",
        "X_train_sel = selector.fit_transform(X_train_scaled, y_train)\n",
        "X_test_sel  = selector.transform(X_test_scaled)\n",
        "sel_feats = X_train.columns[selector.get_support()]\n",
        "print(\"Top-30 selected features:\")\n",
        "print(list(sel_feats))\n",
        "\n",
        "# 8. Define your six models\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
        "    'RandomForest'      : RandomForestClassifier(n_estimators=100),\n",
        "    'GradientBoosting'  : GradientBoostingClassifier(),\n",
        "\n",
        "    'KNN'               : KNeighborsClassifier(),\n",
        "    'DecisionTree'      : DecisionTreeClassifier(),\n",
        "}\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 9. Train, evaluate, save\n",
        "performance = []\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n>>> Training & evaluating {name}\")\n",
        "    model.fit(X_train_sel, y_train)\n",
        "    y_pred = model.predict(X_test_sel)\n",
        "\n",
        "    # Classification report (attack label = 1)\n",
        "    rpt = classification_report(y_test, y_pred, output_dict=True)\n",
        "    atk = rpt.get('1', {})\n",
        "\n",
        "    # Accuracy (overall)\n",
        "    acc = accuracy_score(y_test, y_pred) * 100\n",
        "\n",
        "    performance.append({\n",
        "        'Model'    : name,\n",
        "        'Precision': atk.get('precision', np.nan) * 100,\n",
        "        'Recall'   : atk.get('recall',    np.nan) * 100,\n",
        "        'F1-score' : atk.get('f1-score',  np.nan) * 100,\n",
        "        'Accuracy' : acc\n",
        "    })\n",
        "    # 9c. Save model artifacts\n",
        "    joblib.dump(model, f'{name}.joblib')\n",
        "    with open(f'{name}.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "# Final performance table\n",
        "perf_df = pd.DataFrame(performance).set_index('Model')\n",
        "print(\"\\n## Model Performance on ‘attack’ class:\")\n",
        "print(perf_df.round(2).to_markdown())\n",
        "\n",
        "\n",
        "\n",
        "# 10. Save preprocessing artifacts\n",
        "joblib.dump(scaler, 'scaler.joblib')\n",
        "joblib.dump(selector, 'feature_selector.joblib')\n",
        "\n",
        "# 11. Print performance summary\n",
        "perf_df = pd.DataFrame(performance).set_index('Model')\n",
        "print(\"\\n### Model Performance on ‘attack’ class:\")\n",
        "print(perf_df.to_markdown())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 9. Train, evaluate, save\n",
        "performance = []\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n>>> Training & evaluating {name}\")\n",
        "    model.fit(X_train_sel, y_train)\n",
        "    y_pred = model.predict(X_test_sel)\n",
        "\n",
        "    # Classification report (attack label = 1)\n",
        "    rpt = classification_report(y_test, y_pred, output_dict=True)\n",
        "    atk = rpt.get('1', {})\n",
        "\n",
        "    # Accuracy (overall)\n",
        "    acc = accuracy_score(y_test, y_pred) * 100\n",
        "\n",
        "    performance.append({\n",
        "        'Model'    : name,\n",
        "        'Precision': atk.get('precision', np.nan) * 100,\n",
        "        'Recall'   : atk.get('recall',    np.nan) * 100,\n",
        "        'F1-score' : atk.get('f1-score',  np.nan) * 100,\n",
        "        'Accuracy' : acc\n",
        "    })\n",
        "\n",
        "# Final performance table\n",
        "perf_df = pd.DataFrame(performance).set_index('Model')\n",
        "print(\"\\n## Model Performance on ‘attack’ class:\")\n",
        "print(perf_df.round(2).to_markdown())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiJar0BHPRVT",
        "outputId": "1400b0fa-e6ac-48cf-9104-a7f619a1c72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Training & evaluating LogisticRegression\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            ">>> Training & evaluating RandomForest\n",
            "\n",
            ">>> Training & evaluating GradientBoosting\n",
            "\n",
            ">>> Training & evaluating KNN\n",
            "\n",
            ">>> Training & evaluating DecisionTree\n",
            "\n",
            "## Model Performance on ‘attack’ class:\n",
            "| Model              |   Precision |   Recall |   F1-score |   Accuracy |\n",
            "|:-------------------|------------:|---------:|-----------:|-----------:|\n",
            "| LogisticRegression |        0    |     0    |       0    |      68.3  |\n",
            "| RandomForest       |      100    |     3.61 |       6.97 |      76.07 |\n",
            "| GradientBoosting   |       76.19 |     6.41 |      11.83 |      76.31 |\n",
            "| KNN                |        9.52 |     0.34 |       0.66 |      71.96 |\n",
            "| DecisionTree       |       57.97 |     6.87 |      12.29 |      75.04 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 1. Load data\n",
        "train_df = pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
        "test_df  = pd.read_csv(\"UNSW_NB15_testing-set.csv\")\n",
        "\n",
        "# 2. Handle missing values\n",
        "train_df.fillna(0, inplace=True)\n",
        "test_df.fillna(0, inplace=True)\n",
        "\n",
        "# 3. Define top features and target\n",
        "TOP_FEATURES = [\n",
        "    'dur','proto','state','spkts','dpkts','sbytes','dbytes','rate',\n",
        "    'sttl','dttl','sload','dload','sloss','dloss','sinpkt','dinpkt',\n",
        "    'sjit','djit','swin','stcpb','tcprtt','synack','ackdat','smean',\n",
        "    'dmean','ct_srv_src','ct_state_ttl','ct_src_dport_ltm',\n",
        "    'ct_dst_sport_ltm','ct_srv_dst'\n",
        "]\n",
        "TARGET_COL = 'attack_cat'\n",
        "\n",
        "# 4. Combine train+test for consistent encoding\n",
        "combined = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n",
        "\n",
        "# 5. Fit LabelEncoders on combined data\n",
        "le_proto      = LabelEncoder().fit(combined['proto'].astype(str))\n",
        "le_state      = LabelEncoder().fit(combined['state'].astype(str))\n",
        "le_attack_cat = LabelEncoder().fit(combined[TARGET_COL].astype(str))\n",
        "\n",
        "# 6. Transform features & target\n",
        "combined['proto']      = le_proto.transform(combined['proto'].astype(str))\n",
        "combined['state']      = le_state.transform(combined['state'].astype(str))\n",
        "combined[TARGET_COL]   = le_attack_cat.transform(combined[TARGET_COL].astype(str))\n",
        "\n",
        "# 7. Split back into train/test\n",
        "n_train = len(train_df)\n",
        "train = combined.iloc[:n_train]\n",
        "test  = combined.iloc[n_train:].reset_index(drop=True)\n",
        "\n",
        "X_train = train[TOP_FEATURES].values\n",
        "y_train = train[TARGET_COL].values.astype(int)\n",
        "X_test  = test[TOP_FEATURES].values\n",
        "y_test  = test[TARGET_COL].values.astype(int)\n",
        "\n",
        "# 8. Scale features\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "# 9. Train the RandomForest model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 10. Evaluate\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(\"\\n=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred, target_names=le_attack_cat.classes_))\n",
        "print(\"\\n=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# 11. Save all artifacts\n",
        "joblib.dump(model,           \"attack_category_model.pkl\")\n",
        "joblib.dump(scaler,          \"scaler.joblib\")\n",
        "joblib.dump(le_proto,        \"le_proto.joblib\")\n",
        "joblib.dump(le_state,        \"le_state.joblib\")\n",
        "joblib.dump(le_attack_cat,   \"le_attack_cat.joblib\")\n",
        "\n",
        "print(\"\\nSaved model and preprocessing objects to core/ml_model/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Kes-_IBFG3Z",
        "outputId": "d5268822-27e6-4a7d-92c3-09d450a7ff9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Classification Report ===\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "      Analysis       0.00      0.00      0.00      2000\n",
            "      Backdoor       0.98      0.03      0.07      1746\n",
            "           DoS       0.34      0.54      0.42     12264\n",
            "      Exploits       0.75      0.61      0.67     33393\n",
            "       Fuzzers       0.64      0.26      0.37     18184\n",
            "       Generic       0.93      0.98      0.96     40000\n",
            "        Normal       0.78      0.97      0.86     56000\n",
            "Reconnaissance       0.93      0.73      0.81     10491\n",
            "     Shellcode       0.48      0.42      0.45      1133\n",
            "         Worms       0.68      0.18      0.28       130\n",
            "\n",
            "      accuracy                           0.76    175341\n",
            "     macro avg       0.65      0.47      0.49    175341\n",
            "  weighted avg       0.76      0.76      0.74    175341\n",
            "\n",
            "\n",
            "=== Confusion Matrix ===\n",
            "[[    0     0   964   306    41   138   540     1    10     0]\n",
            " [    0    60   964   452    57   109    74    13    17     0]\n",
            " [    0     0  6643  3517   387   960   549    58   148     2]\n",
            " [    0     0  8429 20393   592  1414  1993   373   192     7]\n",
            " [    0     0   939   598  4752   158 11644    33    59     1]\n",
            " [    0     0   238   250    26 39372    91     1    21     1]\n",
            " [    5     0    16   250  1434     1 54220    56    18     0]\n",
            " [    0     1  1079  1242    90   159   274  7606    40     0]\n",
            " [    0     0    59   161     6    20   351    58   478     0]\n",
            " [    0     0     1    85     0     2    16     0     3    23]]\n",
            "\n",
            "Saved model and preprocessing objects to core/ml_model/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lruBm_TOmXA9",
        "outputId": "d0c54239-7486-49be-eebc-2a2ec26824fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6.1\n"
          ]
        }
      ]
    }
  ]
}